{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7483d7c-e0e3-4900-95ad-f13d6ebdda7e",
   "metadata": {},
   "source": [
    "# Matrix Addition Using the Triton Kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c33e132b-b524-49c8-be8b-5dbcaa609490",
   "metadata": {},
   "source": [
    "No CUDA:\n",
    "- Você pensa em threads individuais.\n",
    "\n",
    "> \"Cada thread soma um número.\"\n",
    "\n",
    "No Triton:\n",
    "- Você pensa em blocos vetorizados.\n",
    "- Você opera em vetores.\n",
    "- O compilador gera o paralelismo.\n",
    "- É uma abstração mais moderna.\n",
    "\n",
    "> \"Esse bloco soma um vetor de números.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6835d4b-8234-46ce-91da-e02ab5d53190",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import triton\n",
    "import triton.language as tl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5844104f-1556-452d-9cf2-aec897622ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "@triton.jit\n",
    "def addition_fn(A_pointer, B_pointer, C_pointer, n_elements, BLOCK_SIZE: tl.constexpr):\n",
    "    # é o nosso BLOCO\n",
    "    pid = tl.program_id(0)\n",
    "\n",
    "    # Cada pid pega um bloco diferente da memória. Isso é como o threadsPerBlock\n",
    "    # [0, 1, 2, ..., 15]\n",
    "    offsets = pid * BLOCK_SIZE + tl.arange(0, BLOCK_SIZE)\n",
    "    # Se a matriz fosse maior que o bloco, isso impediria erro.\n",
    "    mask = offsets < n_elements\n",
    "\n",
    "    # CPU → GPU\n",
    "    A = tl.load(A_pointer + offsets, mask=mask)\n",
    "    B = tl.load(B_pointer + offsets, mask=mask)\n",
    "    # Add\n",
    "    C = A + B\n",
    "\n",
    "    tl.store(C_pointer + offsets, C, mask=mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "878ab34e-81bf-4df0-b709-6d8e8c03c412",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = torch.ones((4, 4), device=\"cuda\", dtype=torch.float32)\n",
    "B = torch.full((4, 4), 2.0, device=\"cuda\", dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "747be187-6c7d-40a0-8525-0390f8acdc99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.]], device='cuda:0')\n",
      "\n",
      "tensor([[2., 2., 2., 2.],\n",
      "        [2., 2., 2., 2.],\n",
      "        [2., 2., 2., 2.],\n",
      "        [2., 2., 2., 2.]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(A)\n",
    "print()\n",
    "print(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7bb73ed9-f735-42a0-906e-40d898849e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "C = torch.empty_like(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f74c5ac7-bcd7-4e0b-8ede-a13f3f271e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_elements = A.numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b8fc7860-33df-4901-842c-b8cfb2e566b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "BLOCK_SIZE = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8c629eff-79a9-4760-9ea6-19a76492faf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = lambda meta: (triton.cdiv(n_elements, meta[\"BLOCK_SIZE\"]),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "77106d3b-4d90-4b40-bce2-5dee1d42388f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<triton.compiler.compiler.CompiledKernel at 0x7f3ffc702f20>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "addition_fn[grid](A, B, C, n_elements, BLOCK_SIZE=BLOCK_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "057c5589-4470-45b9-bbf2-08e8d3840498",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A:\n",
      "tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.]], device='cuda:0')\n",
      "B:\n",
      "tensor([[2., 2., 2., 2.],\n",
      "        [2., 2., 2., 2.],\n",
      "        [2., 2., 2., 2.],\n",
      "        [2., 2., 2., 2.]], device='cuda:0')\n",
      "------------------------------\n",
      "C:\n",
      "tensor([[3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(\"A:\")\n",
    "print(A)\n",
    "\n",
    "print(\"B:\")\n",
    "print(B)\n",
    "\n",
    "print('-' * 30)\n",
    "print(\"C:\")\n",
    "print(C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1486bf7-4681-4359-b5cd-d33450d7432b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
