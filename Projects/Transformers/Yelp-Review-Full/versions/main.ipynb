{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c04dda32-15da-48ec-b9dc-ff67b063ef14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from enum import Enum\n",
    "from tqdm import tqdm\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab24d7d4-26ac-4460-876b-8ec1bf93d6b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ola mundo\n"
     ]
    }
   ],
   "source": [
    "print('ola mundo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "478c9f3b-c2b4-4cf4-a96e-ef1ec1d20fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "from tokenizers import Tokenizer\n",
    "from tokenizers.models import WordLevel\n",
    "from tokenizers.trainers import WordLevelTrainer\n",
    "from tokenizers.pre_tokenizers import Whitespace\n",
    "\n",
    "from tokenizers.models import BPE\n",
    "from tokenizers.trainers import BpeTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e53d578f-97b9-4bb2-87a5-a0473131488e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1a66e5f8-a36a-42bb-88e1-70885ba676e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "67644d27-36c4-479d-99e8-7b9f5c73ae90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f9028d53-8421-430e-a519-31e14da7fe21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['label', 'text'],\n",
      "        num_rows: 650000\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['label', 'text'],\n",
      "        num_rows: 50000\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(\"yelp_review_full\")\n",
    "\n",
    "# Acessar os dados\n",
    "train_data = dataset[\"train\"]\n",
    "test_data = dataset[\"test\"]\n",
    "\n",
    "# Exibir informações sobre o conjunto de dados\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aeca5dd-f605-4c6b-99bc-898362782f5d",
   "metadata": {},
   "source": [
    "# Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "abf4adbe-2413-472c-b4b4-c6affb1842fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpecialTokens(Enum):\n",
    "    PAD = 0\n",
    "    UNK = 1\n",
    "    CLS = 2\n",
    "\n",
    "special_tokens = SpecialTokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "473df20f-95e3-41cf-90f7-8be64301afb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQ_LEN = 256\n",
    "D_MODEL = 64\n",
    "N_HEADS = 8\n",
    "Nx = 6\n",
    "N_OUTPUT = 5\n",
    "VOCAB_SIZE = 5_000\n",
    "LR = 1e-5\n",
    "BATCH_SIZE_TRAIN = 32\n",
    "BATCH_SIZE_TEST = 32\n",
    "EPOCHS = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e119b0f-9a71-4b8c-972f-dc39a5689905",
   "metadata": {},
   "source": [
    "# Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f50535cd-f54e-4fb0-b324-75f32b03bf03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_iterator(data):\n",
    "    for text in data['text']:\n",
    "        yield text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e31bdd5c-e4b4-49b6-883e-e1b35fca4de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_level_tokenizer(data, path_tokenizer: Path = Path('tokenizer/tokenizer.json')):\n",
    "    if not Path.exists(path_tokenizer):\n",
    "        tokenizer = Tokenizer(BPE(unk_token=\"<UNK>\"))\n",
    "        tokenizer.pre_tokenizer = Whitespace()\n",
    "\n",
    "        # Definindo o PAD token como o primeiro na lista de tokens especiais\n",
    "        special_tokens = [\"<PAD>\", \"<UNK>\", \"<CLS>\"]\n",
    "\n",
    "        trainer = BpeTrainer(special_tokens=special_tokens, min_frequency=5, vocab_size=VOCAB_SIZE)\n",
    "        tokenizer.train_from_iterator(text_iterator(data), trainer=trainer)\n",
    "        tokenizer.save(str(path_tokenizer))\n",
    "    else:\n",
    "        tokenizer = Tokenizer.from_file(str(path_tokenizer))\n",
    "\n",
    "    return tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "51a34a79-72e9-40d5-a7ad-b6e367c9e205",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = word_level_tokenizer(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e230b212-b1e4-420a-83d6-71be5ca729bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VOCAB SIZE: 5000\n"
     ]
    }
   ],
   "source": [
    "print(f'VOCAB SIZE: {tokenizer.get_vocab_size()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "f3e42ef7-7a1b-41f7-aaaa-b20993696877",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode('<PAD>').ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d5140d17-db9c-44fe-84f7-0711591969d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode('<CLS>').ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b35adce-dd7d-492e-8bbb-4dfb195b06cb",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "c4c8ad34-0990-4b80-bd0b-3685b827a899",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple, List\n",
    "\n",
    "class YelpReviewFullDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer: Tokenizer = tokenizer, seq_len: int = SEQ_LEN) -> None:\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.CLS_token_id = 2\n",
    "        self.PAD_token_id = 0\n",
    "        self.seq_len = seq_len\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return self.data.num_rows\n",
    "        \n",
    "    def __getitem__(self, id_i) -> Tuple[int, List[int]]:\n",
    "        item = self.data[id_i]\n",
    "        label, text = item['label'], item['text'].lower()\n",
    "        tokens_list = [self.CLS_token_id] + self.tokenizer.encode(text).ids\n",
    "        tokens_list = self.truncate_seq(tokens_list)\n",
    "        return {'label': label, 'tokens': torch.tensor(tokens_list), 'text': text}\n",
    "\n",
    "    def truncate_seq(self, tokens_list: List[int]):\n",
    "        len_token_list = len(tokens_list)\n",
    "        if len_token_list > self.seq_len:\n",
    "            return tokens_list[: self.seq_len]\n",
    "        elif len_token_list < self.seq_len:\n",
    "            return tokens_list + [self.PAD_token_id] * (self.seq_len - len_token_list)\n",
    "        return tokens_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "91db676a-2cfe-42af-8759-30652c6ee4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = YelpReviewFullDataset(train_data)\n",
    "test_dataset = YelpReviewFullDataset(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a1c7ad2a-d99e-41b5-a0b3-8329eddf23d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, shuffle=True, batch_size=BATCH_SIZE_TRAIN)\n",
    "test_loader = DataLoader(test_dataset, shuffle=True, batch_size=BATCH_SIZE_TEST)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "177b4371-57e7-4f56-8f08-ac7b76310897",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "0bafe789-f9e8-4aa7-b0cd-37f46f00d6c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    \"\"\"\n",
    "    https://pytorch.org/tutorials/beginner/transformer_tutorial.html\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, d_model, seq_len, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        pe = torch.zeros(seq_len, d_model)\n",
    "        position = torch.arange(0, seq_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(\n",
    "            torch.arange(0, d_model, 2).float()\n",
    "            * (-math.log(10000.0) / d_model)\n",
    "        )\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer(\"pe\", pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:, : x.size(1), :]\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "a7933c98-257d-422f-bdcb-10eb708e1bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class YepReviewModel(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        seq_len: int = SEQ_LEN,\n",
    "        d_model: int = D_MODEL,\n",
    "        vocab_size: int = VOCAB_SIZE,\n",
    "        num_heads: int = N_HEADS,\n",
    "        n_x: int = Nx,\n",
    "        dropout: float = 0.0,\n",
    "        n_outputs: int = N_OUTPUT\n",
    "    ):\n",
    "        super().__init__()\n",
    "        # configurações do modelo\n",
    "        self.seq_len = seq_len\n",
    "        self.d_model = d_model\n",
    "        self.vocab_size = vocab_size\n",
    "        self.num_heads = num_heads\n",
    "        self.n_x = n_x\n",
    "        self.dropout = dropout\n",
    "        self.n_outputs = n_outputs\n",
    "\n",
    "        # componentes\n",
    "        self.embedding_layer = nn.Embedding(\n",
    "            num_embeddings=self.vocab_size, \n",
    "            embedding_dim=self.d_model, \n",
    "            padding_idx=SpecialTokens.PAD.value)\n",
    "        self.encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=self.d_model, \n",
    "            nhead=self.num_heads,\n",
    "            dropout=self.dropout, \n",
    "            norm_first=True, \n",
    "            batch_first=True,\n",
    "            activation=\"gelu\"\n",
    "        )\n",
    "        self.encoder_block = nn.TransformerEncoder(self.encoder_layer, num_layers=self.n_x)\n",
    "        self.linear_layer = nn.Sequential(\n",
    "            nn.Linear(self.d_model, 124),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(124, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, 8)\n",
    "        )\n",
    "        self.output_layer = nn.Linear(8, self.n_outputs)\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.5\n",
    "        self.embedding_layer.weight.data.uniform_(-initrange, initrange)\n",
    "        \n",
    "        self.linear_layer[0].weight.data.uniform_(-initrange, initrange)\n",
    "        self.linear_layer[0].bias.data.zero_()\n",
    "\n",
    "        self.linear_layer[2].weight.data.uniform_(-initrange, initrange)\n",
    "        self.linear_layer[2].bias.data.zero_()\n",
    "\n",
    "        self.linear_layer[4].weight.data.uniform_(-initrange, initrange)\n",
    "        self.linear_layer[4].bias.data.zero_()\n",
    "\n",
    "        self.linear_layer[6].weight.data.uniform_(-initrange, initrange)\n",
    "        self.linear_layer[6].bias.data.zero_()\n",
    "\n",
    "        self.linear_layer[8].weight.data.uniform_(-initrange, initrange)\n",
    "        self.linear_layer[8].bias.data.zero_()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding_layer(x)\n",
    "        x = self.encoder_layer(x)\n",
    "        # Pegando a representação vetorial do token <CLS>\n",
    "        x = x[:, 0, :]\n",
    "        x = self.linear_layer(x)\n",
    "        x = self.output_layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "120e155f-22bb-4117-9b80-289dc640bd67",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YepReviewModel().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "4aa9b01e-1fbb-4dc8-b98f-c3ad1fcb32b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                                            Param #\n",
       "==========================================================================================\n",
       "YepReviewModel                                                    --\n",
       "├─Embedding: 1-1                                                  320,000\n",
       "├─TransformerEncoderLayer: 1-2                                    --\n",
       "│    └─MultiheadAttention: 2-1                                    12,480\n",
       "│    │    └─NonDynamicallyQuantizableLinear: 3-1                  4,160\n",
       "│    └─Linear: 2-2                                                133,120\n",
       "│    └─Dropout: 2-3                                               --\n",
       "│    └─Linear: 2-4                                                131,136\n",
       "│    └─LayerNorm: 2-5                                             128\n",
       "│    └─LayerNorm: 2-6                                             128\n",
       "│    └─Dropout: 2-7                                               --\n",
       "│    └─Dropout: 2-8                                               --\n",
       "├─TransformerEncoder: 1-3                                         --\n",
       "│    └─ModuleList: 2-9                                            --\n",
       "│    │    └─TransformerEncoderLayer: 3-2                          281,152\n",
       "│    │    └─TransformerEncoderLayer: 3-3                          281,152\n",
       "│    │    └─TransformerEncoderLayer: 3-4                          281,152\n",
       "│    │    └─TransformerEncoderLayer: 3-5                          281,152\n",
       "│    │    └─TransformerEncoderLayer: 3-6                          281,152\n",
       "│    │    └─TransformerEncoderLayer: 3-7                          281,152\n",
       "├─Sequential: 1-4                                                 --\n",
       "│    └─Linear: 2-10                                               8,060\n",
       "│    └─ReLU: 2-11                                                 --\n",
       "│    └─Linear: 2-12                                               8,000\n",
       "│    └─ReLU: 2-13                                                 --\n",
       "│    └─Linear: 2-14                                               2,080\n",
       "│    └─ReLU: 2-15                                                 --\n",
       "│    └─Linear: 2-16                                               528\n",
       "│    └─ReLU: 2-17                                                 --\n",
       "│    └─Linear: 2-18                                               136\n",
       "├─Linear: 1-5                                                     45\n",
       "==========================================================================================\n",
       "Total params: 2,306,913\n",
       "Trainable params: 2,306,913\n",
       "Non-trainable params: 0\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "629dec2f-8ab8-4608-9821-fa943f858063",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "18815bbb-4ca2-4ce8-a515-70a18340d5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def acc_metric(label, output):\n",
    "    output = torch.argmax(output, dim=1)\n",
    "    return (label == output).float().mean().detach().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "aa3540bb-dee2-4066-b5c8-0898e6f3107e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': tensor([0, 3, 0, 0, 3, 2, 0, 4, 4, 3, 2, 1, 4, 2, 0, 4, 2, 3, 2, 0, 4, 0, 0, 3,\n",
       "         1, 4, 4, 1, 3, 4, 1, 1]),\n",
       " 'tokens': tensor([[   2,   47, 1911,  ...,    0,    0,    0],\n",
       "         [   2,  244,  466,  ...,    0,    0,    0],\n",
       "         [   2, 3123,  650,  ...,    0,    0,    0],\n",
       "         ...,\n",
       "         [   2,  852,   39,  ...,    0,    0,    0],\n",
       "         [   2,  453,   79,  ...,    0,    0,    0],\n",
       "         [   2,   47, 2683,  ...,   47,  626,  415]]),\n",
       " 'text': [\"i hate this place. its always a long wait & every time i've came here dr.trafreshi  just sits on his laptop hardly looking up.. he seems to not care by any means! and anytime i voice my concerns about something he not only minimized them but acts as if i make it up!\",\n",
       "  'great german food, portions are huge. the beers are brewed on the premises noisy place, great environment to hang  out with friends.',\n",
       "  \"2nd visit. great food menu when i visited the 1st time! however, probably never ever going to sit at the bar ever again. bartender had the bar skills of a 10 year old.  i sat at the bar, took the bartender 5 minutes to acknowledge me. i was the only one at the bar. then when he finally acknowledged me, asked what i would like. i asked if he had any moscato. he had no idea what that was. then the phone rings, he answers then leaves me for ten minutes without taking my order. then a server & a chef also passed by me asking if i needed anything. i told them i'd like to place an order as the bartender deserted me after i got trumped by a phone call that he took. they both giggled then moved on. what? who trained them? lack of customer service in a customer service, hospitality oriented city? terrible!\",\n",
       "  \"tom colicchio should pack his knives and go. this restaurant is mediocre at best. we had a reservation and still waited for almost 45 minutes for our table to be ready. the hostess never checked in with us and we had to repeatedly double check on whether our table was ready or not. there is hardly a waiting area and the servers running between tables were very rude and acted put out when asking us to move out of their way. there is literally nowhere comfortable to stand. \\\\nthe food is uninventive and uninspired. there were 6 of us and we ordered lobster bisque, which was good but served lukewarm, oysters, that were not shucked properly, and a caesar salad, which was nothing special.  we all had steak, which for the price was not worth it, not cooked correctly, and strangely seasoned. as for the sides,tom colicchio, as a top chef judge, should really be ashamed. the best part of the meal were the parker house rolls and the wine.  \\\\nthe best part of the dinner was the service, which was very good. \\\\n\\\\nmy recommendation is to go somewhere else, especially if you have a large party, and especially if you're willing to drop a lot of money for food that should fit the price.\",\n",
       "  \"went to see local bands play here last night with amy d and her awesome friends.  totally my kind of bar...dark, dirty, divey, and with killer bands playing.  very spacious...but that could have something to do with the fact that the place wasn't really packed. \\\\n\\\\ni didn't drink this night, but i did notice that budweiser was $6.  (not a beer drinker, but that seems a little high, i think)  but somebody was buying the drinks.  i think last night was the first time i actually had a guy fall on top of me. (and i guess my response was priceless)\\\\n\\\\nthe bar is in a strip mall, so parking wasn't too bad.  (i think that i came at the right time, but be careful where you park or you may get towed) \\\\n\\\\nthe most important part of the night was that i saved amy d's life...i removed a splinter from her hand.  i rock!\\\\n\\\\npeace!\",\n",
       "  \"the shop itself is adorbs.  located in the baxter town center just off of i77, it was easy to find right next to the starbucks.  there is some parking on the street (good luck), but there is a ton of parking behind the stores where you have room to move and don't have to dodge oncoming traffic.  \\\\n\\\\nhad i only eaten the swiss roll cake cupcake that i ate in the charming shop (shabby chic with lots of color and personality), they would have gotten a 4 and *maybe* even a 5 - it was moist, delicious and full of flavor (a moist chocolate cupcake with marshmallow filling, topped with chocolate icing, a vanilla drizzle and a cut of a swiss cake roll).  alas, i brought a vanilla/vanilla home and it was terrible.  the icing was okay, with a baby bear quantity (juuuust right) on top, but the cake was bad.  dry, odd flavored.  just bad.  i ate about two bites and threw the rest out.  i have a chocolate with vanilla icing still in the box, and i am in no hurry to eat that after the vanilla/vanilla - it was bleh.\\\\n\\\\nthey also had gluten free cupcakes, cake pops and iced sugar cookies.  beverages available and reasonably priced.  my 3 cupcakes were put in a sturdy box.\\\\n\\\\n4 stars for the swiss cake cupcake, 1 for the vanilla/vanilla, 4 for the shop with friendly employees.  it was just over $10 for the 3 cupcakes.  if i find myself in ft mill again, i would stop in for a swiss cake, but i won't be making a special trip.\",\n",
       "  'i hate this place',\n",
       "  \"what's not to love living here?! the center of downtown phoenix with great views of our valley from every direction. quality construction throughout and friendly staff to assist you in whatever you need. the non smoking building policy was exactly what my wife needed as she has asthma. we have owned many homes and have no desire to own any more. thanks for providing such a great place to call home.\",\n",
       "  \"i came here on a sunday for lunch with the bf and thought this place was awesome, especially since the reason i came here was due to a travelzoo coupon, $20 for 2 ppl; 2 aguas frescas, 2 entree's, and a dessert. \\\\n\\\\nlove that this place gives free chips and dip, not to mention how yummy the (i think) banana or could be plantain chips were w/ the mango salsa. \\\\n\\\\ndrinks: i got a beer and was upset that they didn't have anything on draft and the only bottles beer that i ordered was out, so i had to settle for something else. i think they could have stocked this place better, but then again, it was a sunday lunch day... perhaps they were in the process of ordering more. with our voiuchers we each ordered a aguas frescas, i thought the sweeter pineapple definitely triumphed the orange, but both were really good. the orange was a bit more watery.  \\\\n\\\\nentree's: first entree was the teberna's steak tacos, which i thought the meat was cooked to perfection and the flour tortilla was delish. however, i didn't care for the rice and beans too much. the second entree, the shrimp salad had large meaty shrimps that were juicy and grilled w/ a yummy seasoning. the sald part, could have used more dressing or a dressing with more flavor. \\\\n\\\\ndessert: we shared the flan. to be honest, i'm not a big fan of flan to begin with, but i can definitely eat a nice soft flan, so that was what i was hoping for. instead, this flan, definitely tasted of flan but had more of a cheescake texture, thick and creamy. it was good, but even with both of us sharing it, we weren't even able to finish this rich dessert.  \\\\n\\\\nall in all, i give this place a 4-star for food, but with my coupon have bumped them up to a 5-star. how can you beat all that for $20?\",\n",
       "  'sashimi was fresh, but fried chicken was dry.  i adore the decoration of this place.',\n",
       "  \"legume is one of the nicest restaurants in oakland, but it's obvious they're aware of that fact when setting the prices.  the food is good, but not so amazing that one couldn't find a better meal for less money in another neighborhood.  that said, the rotating menu makes it a little hard to rate, as unsuccessful dishes can be quickly swapped out for other options.  this place has potential to be a great restaurant, but it has a bit of a learning curve to get through first.\",\n",
       "  'i wanted to like this place, it has a lot going for it.\\\\n-awesome location\\\\n-perfect ambience\\\\n-spot on decor\\\\n-good standard irish pub beers on tap\\\\nbut sadly prices were a little high, and our bar tender wasnt very attentive\\\\na smithwicks and a newcastle set me back $11 + tip\\\\nthis was during happy hour no less\\\\npffffff\\\\nweak',\n",
       "  'i love this grocery store!  i wish there was one closer to my house but its okay i have alot of great places in my area too...anyways i have always loved going here for groceries...especially for specialty stuff and i think their frozen meals are the best and second to none!  my boyfriend loves their coffee and i love their hummus!  i love how they set up their stores and its such an inviting and fun atmosphere!  if you like fruit bars try the high fiber fruit and veggie bars they are good for you and they are good!  their wine selection is awesome too; especially for being a smaller grocery store, but i really like their white wine selection.  go here and shop shop shop!!!!',\n",
       "  \"this was our first visit to the sugar factory. now we had a huge party of 17 so we expected to wait a long time, however the wait was about 30 minutes. we browsed the candy store portion while we waited. \\\\n\\\\nnow the candy part was super cute and trendy. and like all trendy things expensive! we did receive a fair amount of free samples of the gelato. my kids instantly found the couture pops surrounded by pictures of all the famous people who love them as well. so thanks sugar factory for the 3 $25 lollipops i was talked into buying. luckily we received a refill pack for free. \\\\n\\\\nwe were seated and the decor was nice. our waitress was friendly. the food: my husband and i shared a rosemary chicken caesar salad and a bleu cheese burger. the burger was fabulous! the salad not so much. the chicken was dry and the lettuce pieces were whole not chopped. my kids had chicken fettecini. the chicken tasted like it was boiled and the sauce was bland. the bar b q pizza was good. but it's just that. nothing fancy. the tea was $4 and soft drinks were $3.50. \\\\n\\\\nmy daughter and nephew received a chocolate cupcake for their birthday. the frosting was good but the cake itself was dry. i also purchased a small red velvet cupcake for $5. way over priced. it was pretty good, a tad dry which is easy for red velvet. we took the kids back for the gelato. the smallest cups were $5 too. \\\\n\\\\nso overall it was more of a fun ambiance rather than exceptional dining. for me, my husband and 3 kids(not counting the baby) $100 for lunch and another $100 for ice cream and courure pops. ouch! it definitely was comparable to any other restaurant on the strip price wise so just be prepared.\",\n",
       "  \"i'm  giving this one star because not only did anyone not know whether there is a website for this place, but the general website i was given is no longer available.  no one seemed to know if there is a menu online but took my e-mail address so they could send me one from the previous occupant kennedy.   they also told me that it would take a while to send this e-mail because there is no computer onsite.  really???   presidio has been open for nearly a year according to the person on the phone.  does this send a red flag about the service here?   let's hope it's better inside.\",\n",
       "  \"the only bad thing - service was a little slow - not too much, but if we had been in a rush, we would have had problems.\\\\n\\\\nother than that - a huge selection of domestics and imports at really really really reasonable prices. the dinner appeased everyone in our group - there really is something for everyone: the nacho/wing lover can have her fix, the steak and potatoes lover can be very satisfied, and the fish/veggies girl can get her fix. everything was cooked perfectly, and we all loved the sweet potato hash (a home-fries type of thing with white and sweet potatoes). \\\\n\\\\nthe waitress was nice and knowledgeable and honest about the beers and the menu, and was dead on with her personal recommendations. \\\\n\\\\nas we were leaving, they were setting up for their live band set  - it's a kind of tight space for the dining room, so i'm guessing it was going to be very loud and unfriendly to conversations (while we were there the jukebox was playing some current pop/hip hop/ great rock and the noise level was just above a regular conversation level).\\\\n\\\\nall in all - nice place, and worth the trip from down town, definitely\",\n",
       "  'i hear a lot of people bragging about growing up in \\\\\"insert your northeastern city here\\\\\" and how great the pizza is there.  pizza should be like this.  pizza should not be like that.  blah, blah, blah.\\\\n\\\\nthe way i see it, i had it good growing up in the middle of nowhere.  i grew up eating chain store pizzas and loved it!  and now that i\\'m all grown up i not only appreciate great pizza (hard to find), but i also enjoy good cheap macro produced pizza.  it all has its place.  and when i want a fast, cheap pizza domino\\'s does the trick.\\\\n\\\\ni prefer the pepperoni and salami (recommended by my fiance who will never admit to it), but also really like the double bacon.  two mediums two toppings for twelve bucks.  home alone for the weekend?  boom.  \\\\n\\\\nfive star it ain\\'t.  but if you aren\\'t snobbish about pizza and what you think it ought to be, domino\\'s is a tasty way to spend a meal.',\n",
       "  'it has been a while since i last visited toast, but my previous sentiments still hold true - this place is great!\\\\n\\\\nwe went with a small group on a friday night.  they were kind enough to seat us  in a semi-private room upstairs.  this is such a neat space.  it\\'s an old two-story house that has been converted into an upstairs and downstairs with a full-bar downstairs.\\\\n\\\\nnotable stand-outs on the menu were: shrimp and grits (at least get the appetizer portion if you aren\\'t going to do the entree size).  the shrimp were large and i think we got 3 or 4 of them in the app size.  the tasso ham was delicous and bacon-y.  the grits were cheesy and awesome.  this was a super hearty and filling appetizer that everyone loved.  \\\\n\\\\ni got the burger which would best be described as close to the best home-style, backyard bbq type burger you can imagine.  it was nothing overly fancy and it wasn\\'t trying to be more than just a burger.  but it was a really good burger.  perfectly seasoned, lettuce, tomato, onion and ultra fresh fries.  i mean, \\\\\"did you just pull these from the ground, wash them, slice them and fry them\\\\\" fresh.  even my wife said the fries were delicious, and she\\'s a fry snob.\\\\n\\\\nmost of the other guests got the hanger steak.  the steak looked good, but i\\'m still glad i got the burger.  they nailed the temp on everyone\\'s entree.  med rare was med rare, medium well was perfect too.  everyone finished their entrees - a good sign.\\\\n\\\\ni\\'d say the desserts were the low spot of the meal - not terrible, just not memorable.\\\\n\\\\nall in all, we were very pleased with our visit and i\\'m glad that groupon got me to try a place i had almost forgotten about.\\\\n\\\\ni\\'ll be going back for the wednesday special - burger, beer, and a bourbon for $14!',\n",
       "  \"wow wow wow...what a simplistic spectacle!  this pure white restaurant greets you with girls in orange dresses and tanks of large orange goldfish.  the contrast of these colors is magnificent and definitely something you don't get to see everyday.  very cool. \\\\n\\\\nthe food on the other hand....eh...kinda standard.  the chef stationed right in front of the restaurant is pulling noodles for all to see like he was some sort of zoo animal.  hand pulled noodles are all the rage right now so you just have to let it be.  given that, we ordered noodles with thin sliced beef and a singapore noodle dish with curry.  both dishes eatable and decent...neither dish worth going back for.  prices were too high but since this is las vegas, anything goes i suppose (yes that rhymed.)  \\\\n\\\\nadvice....stop by and see this place...but don't eat here unless you are starving and willing to overpay.\",\n",
       "  \"i agree with the other reviewers. i came in for a mole check and they ended up removing 3 moles  they didn't inform me how much it would be to remove them. i told her my insurance isn't great and i was worried about the cost. i ended up paying almost $1,000 for everything which is ridiculous and now have three ugly scars. i've been going to  dermatologists for years and this is the first dr who removed this many moles. it's definitely about getting your $ at this place.\",\n",
       "  'the word \\\\\"vegan\\\\\" elicits connotations of only bad things in my mind. a vegan freaking donut shop ? how is this possible? for a long time i stayed far far away thinking good vegan food was impossible!\\\\n\\\\ni finally caved and bought a box of assorted things to bring into work. i bragged about how these were vegan and how cool that was, but yeah, when you work in a corporate office and everyone is 45+ vegan is a bad word to them too. no one would even try the donuts once i said they were vegan. oh well, so i threw most of them out. the ones i tried, however, were phenomenal! awesome donut holes, and the best cinnamon twist i\\'ve ever had in my life. yup, that good. \\\\n\\\\nok so i will leave you with this: a) not all the donuts in there are vegan, but ask and the staff will guide you to the vegan ones if that is your preference. b) the donuts i had from there were so damn good i\\'m convinced the vegan thing is a fake and they can\\'t possibly be lard/butter/etc free. good thing i\\'m an animal eating freak so it\\'s cool if it\\'s a scam, whatever, i\\'ll still buy them!',\n",
       "  \"this is the most depressing zoo i've ever been to. it must be the san quentin of zoos, all the animals are in lockdown. \\\\n\\\\nit is essentially a dusty lot crammed full of small concrete cages. all the animals look depressed and must be suffering from mental anguish. there are some cool animals in there, but they are all in pain. the only animals that were happy were the millions of chickens and roosters running amok in that place. \\\\n\\\\nthe place was just downright depressing, never been to a zoo this bad. it should be a crime.\",\n",
       "  'i truly thought i\\'d found a great place when all tests are done in the same location and it\\'s a \\\\\"one stop shop\\\\\"!  i loved my no-nonsense doc, dr. delorenzi, but the office practice of having patients call themselves to check on what is covered on their insurance is a pain.  having been a patient there a number of years, i called to complain but got little help from the office manager.  also recently they sent me a notice they dropped blue cross blue shield, so i had no recourse but to go to another doctor.  now i get a message they have reinstated blue cross?  what\\'s up, warner practice!',\n",
       "  'i was a little confused as i walked up to cotterell lighting store in the newington area. i was presented with what appeared to be a beautiful old church but the \\\\\"sale now on\\\\\" said something different. then, i noticed the huge signs for \\\\\"cotterell lighting\\\\\" and i decided to pop in. i was still really confused and wondered if i was entering some kind of bizarre lighting cult.\\\\n\\\\nas soon as i entered i realised that it was indeed a shop, and it sold lighting, all kinds of lighting, in every design you could think of. there were two friendly staff members working who just told me to give them a shout if i needed any help so i decided to browse. i couldn\\'t believe how many different lighting styles they had and if you\\'re looking for a new lampshade or light then you will find exactly what you\\'re looking for here. in addition to lighting they also do a small amount of furniture.\\\\n\\\\ni noticed a really cool mirror ball light, a lampshade on a stand that was designed to look like a fish bone and a huge mirror that i like instantly as it made me look better than i actually do.\\\\n\\\\ni have to admit, it was a little odd walking around an old church and it was pretty much intact apart from the missing pews. when i looked up i could see that the upper seating of the church was still there and if that area was still accessible you could have taken a seat and looked down at the now lighting shop. the creaking floor boards were still there as were the stained glass window and painted high ceiling. it seems a waste that such a beautiful church is now just a shop and even stranger that it hasn\\'t been disguised as a shop.\\\\n\\\\ni\\'d recommend visiting under the guise that you need a new lightbulb, as it really is an experience.',\n",
       "  \"i should have read the reviews before we ate there but i didn't.  i was not impressed with the lasagna at all.  the sauce was very bland and there was very little meat or ricotta cheese in it.  it was mostly noodle.  my husband had the lobster ravioli which as better than my lasagna but still not that great.  i used a restaurant.com certificate so that helped but i don't think it would be some place i will go back to when i am in vegas again.\",\n",
       "  \"i feel like i need to emphasize that this is my favorite restaurant. food, experience, service, everything. but mostly, the food. lets get to it. \\\\n\\\\nclassic izakaya aka beer, drinking food, good times. i usually have to get a few items. yellowtail tartare, beef tataki, grilled salmon belly, agedashi tofu, sashimi salad and uni mochi. from there i like to switch it up picking and choosing a few items from the menu and the wall! sashimi salmon and yellowtail, okonomiyaki, oysters with ponzu sauce, beef tongue stew, seafood quesadilla, jalape\\\\u00f1o fried rice, etc list goes on and on. and on.\\\\n\\\\ni visit vegas maybe once or twice a year. i frequent ichiza as many times. it is pretty close to the strip (not really walking distance, take a cab!) and it's located in chinatown. if you have a large party, they do accommodate but call and make a reservation! now eat there! really. eat there. now. \\\\n\\\\noh! dessert! try the honey toast. better to share. pretty amaze.\",\n",
       "  \"suddenly without any notice, they are closed.  went there on wednesday march19th and 3 days later, on saturday, park discount cleaners  is emptied out with a hand written note on the door; closed  pick up your cleaning  across the street at a competitor's company !!    this was the best cleaners, the only place i would go.  all cleaning done on the premises. so if anyone knows what happened  or why charlie, the owner,  went out of business... please notify everyone.\",\n",
       "  'let me start off with the positive: everyone here is super nice. my dog loves the staff here. the follow up is nice, i enjoyed getting a call to see how my baby was doing after our visit. also, i went in with my friend when her cat passed away and they were so sweet. anyone with an animal knows that\\'s one of the toughest things to go through, and they were great with my friend. \\\\n\\\\nnot so good... and it\\'s funny because i\\'ve seen this term used in other reviews (and here i thought i was being all original)... is that i feel like i\\'m at a used car lot. i bring the dog in, there\\'s \\\\\"something\\\\\" wrong that they look into, and after several tests and a ton of money later that magically isn\\'t included in the monthly fee i pay for.... there still isn\\'t an answer. i can tell you, as can anyone around him, that i have one of the healthiest and happiest dogs in the world, and what they assumed was wrong with him would make him lethargic, withdrawn, have a loss of appetite, and he\\'s quite the opposite. i was also told that i\\'d be refunded whatever money i didn\\'t use from the plan i pay for (i probably used 1/3 of it at most), and still haven\\'t heard back from them. \\\\n\\\\nsadly, i\\'m on the lookout for another vet for my fur kid. but like i said, they were awesome for one of my good friends throughout her cat\\'s life... maybe they\\'re just better cat vets?',\n",
       "  'i was all set to write this place off as completely over-rated, but i have to admit, this buffet is pretty darn good. usually, the line for this buffet is ridiculous. my visit to vegas this time was mid-week, and i was fortunate enough to choose a good time to chow down, as the line was a scant 20 people deep.\\\\n\\\\npretty interior, lots of seating, interesting sections which gave you a feeling like there was inside seating and outside seating because of little \\'rooms\\' within the seating area. \\\\n\\\\nplenty of choices to satisfy most cravings. standard buffet fare and some non-standard selections as well. most people gravitate to the crab legs at buffets, i\\'m more of a prime rib kinda gal. the prime rib here was pretty good. i admit, i grabbed some of the mushroom sauce meant for the chateaubriand instead of the au jus. i think it was a good choice. \\\\n\\\\nother items i had were the brussel sprouts (don\\'t judge me), kielbasa and sauerkraut, chicken with a wine/mushroom sauce. all very, very good. desserts were plentiful. i tried a creme brulee and a puff thing that i have no idea what it was called but it was damn good.\\\\n\\\\ni\\'m not sure i liked this buffet enough to pay the single visit price and wait in the usually long line. i had purchased the \\\\\"buffet of buffets\\\\\" deal, so it was worth it in this case. \\\\n\\\\nthe food is very good, service was great. as soon as i went up for dessert, a staff member came by and offered me coffee. it\\'s like she read my mind. if you\\'re a multiple plate buffet champ, it\\'s probably worth the wait and the price. if you\\'re like me and a 1-plate wonder, maybe spend your $30 elsewhere.',\n",
       "  'quite a charming place to dine! think of paradise bakery...but way better! excellent house coffee. i look forward to visiting again :)',\n",
       "  \"new to town my boyfriend and myself went due to the raving reviews. honestly we were pretty disappointed. i used to work in a mexican restaurant that was rating the best by the state and i didn't recognize half the food. also i though it was strange my dish came with  coleslaw....and i'm pretty sure it was spoiled. the food was mediocre , but not excellent. my boyfriend insisted the chips tasted like sweat. but the reason i wont go back is their margaritas. you get the choice of size and flavor, that's it . i figured i start off with a basic strawberry and i had 2 by the end of the meal. they were not worth it. 4 margs came to $34!! i was baffled. pass\",\n",
       "  \"i hadn't been to a red robin for a while and remembered really liking it (as far as a chain burger is concerned).  when my husband asked me to meet him there for lunch after he and his daughter were done shopping, i readily agreed.  \\\\n\\\\nbig mistake.\\\\n\\\\n1.  filthy.  really disgustingly dirty.  there were plates and food on tables that was there before we got there and was still there when we left over an hour later.  our waitress spilled some iced tea on the table and the floor next to us while she was pouring.  i'm going to guess 4 oz or so.  no big deal - it happens... but then, she didn't clean it up.  we were probably there another 20-30 min after the tea... there was still a puddle on the floor.  \\\\n\\\\n2.  miserable service.  i got there last & my husband had asked the server to bring me water so it would be on the table when i got there.  that was there... but she never refilled it or asked me if i wanted anything else.  i wanted a soda - but never had the opportunity to order it.  my husband had also asked before i got there, when i sat down and again when we ordered, if we could have a basket of fries as a starter (we ordered burgers, so it was part of our food).  they didn't get there until the rest of our order got there.  i was there over 30 min before we got food - he'd been there almost 10 min before me.  40 min.  and it wasn't particularly busy.  there were a few groups at tables, but at 3pm on a sunday - the place was over 50% empty.  we weren't checked on, even after we had issues with the food (see below).  \\\\n\\\\n3.  mediocre (at best) food.  when we finally did get food, it was mediocre at best.  my fries were ice cold.  they felt like they'd been sitting under the ac duct for a while.  i actually refused them because they were so cold.  my burger was passably warm and not particularly tasty.  it wasn't horrible, but it wasn't wasn't great.  i could make something better at home.  my husband's burger was even less warm than mine.  he said it was ok, but would have probably been tasty if it was warm.  his daughter had a turkey sandwich and soup.  she says hers was excellent.... so 1/3 of the party was happy.\\\\n\\\\ni will not be going back to this location for any reason.\"]}"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "68cfdcac-e241-45ef-8d07-919adc54f3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(train_loader))\n",
    "batch_labels, batch_tokens, batch_texts = batch['label'], batch['tokens'], batch['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "b151f1e2-6334-46ca-9b81-bf0f64c9baa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### TEXTO ####\n",
      "chompies is great, i love the corned beef & pastrami sandwich..the food is very tastey..also if you want some amazing pancakes try the wheat stuffed granola ones they are out of this world.. on shea the chompies on shea has one problem, its the service, now the servers are nice & all but they seem to maybe be understaffed, takes forever to get your order. another thing that caused me to give it 3 stars is the price, chompies is pretty darn expensive, expect to pay about $15-$20 for a basic breakfast, i only order 2 eggs, potatos & dry toast & sometimes pancakes..when i go there for lunch & get the corned beef sandwish, fries, & a drink its about $25..but the portions are large & u will definitley not leave there hungry!\n",
      "## Label: 2 ##\n"
     ]
    }
   ],
   "source": [
    "print('#### TEXTO ####')\n",
    "print(batch_texts[0])\n",
    "print(f'## Label: {batch_labels[0]} ##')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "df3463a0-7bac-443f-b260-a05a18aafd75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2251, -0.4110, -2.2903,  4.9426,  1.9228]], device='cuda:0',\n",
       "       grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(batch_tokens[:1, :].to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "a873cfde-0cb3-43cd-a790-e1f0b458e75d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[   2,  547,  465,  635,   86,  244,   14,   47,  441,   70, 4983,\n",
       "           907,    8, 4853,  644,  122,   70,  176,   86,  167,  692,   63,\n",
       "           122,  338,  175,  117,  325,  196,  668, 2344,  347,   70, 4522,\n",
       "          2393,  309, 3283,  649, 1332,  135,  140,  137,   96,  136, 1745,\n",
       "           122,   78,  281,   39,   70,  547,  465,  635,   78,  281,   39,\n",
       "           352,  149, 1183,   14,  483,   70,  242,   14,  267,   70, 1609,\n",
       "           140,  339,    8,  145,  128,  135, 1241,   79,  744,   99,  667,\n",
       "          4086,   14, 1786, 2220,   79,  186,  288,  326,   16,  538,  188,\n",
       "           119,  265,  701,   92,   79,  536,   82,   21,  659,   86,   70,\n",
       "           509,   14,  547,  465,  635,   86,  413, 4654, 1105,   14,  603,\n",
       "            79,  629,  262,    6,  891, 4678,  720,  106,   39, 2454,  836,\n",
       "            14,   47,  298,  326,   20, 1479,   14,  958,   57,    8, 1056,\n",
       "          1683,    8, 1643, 2344,  122,  234,   47,  177,  180,  106,  592,\n",
       "             8,  186,   70, 4983,  907,  613, 1191,   14,  729,   14,    8,\n",
       "            39,  386,  483,  262,    6, 1554,  122,  128,   70, 1376,  140,\n",
       "           869,    8,   59,  294,  530,   82, 1505,  138, 1188,  180, 1705,\n",
       "             3,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0],\n",
       "         [   2,  176,   93,  468,  525,  614,  631,  293,   96,   39, 1555,\n",
       "            15, 1171, 1247,  320, 1915, 1287,  176,   16,   82,   93,  745,\n",
       "           413,  906,  128,  338,  176,   93, 3553,   16,  242,   93,  468,\n",
       "            16,  183,   93,  339,   80,  623,   16,  287,    9,   58,  461,\n",
       "            47,    9,  111,   99,  451,  257,   16,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0]]])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_tokens[:2, :].unsqueeze(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd5aa01b-7c3e-4803-b579-de00fd77cc8d",
   "metadata": {},
   "source": [
    "# Treinando em uma Amostra\n",
    "Isso ajuda a ver se o modelo está convergindo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "2fed80dc-5f2f-4090-9c95-316e311feb6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                             | 175/1000000 [00:01<2:07:01, 131.18it/s, loss=0.499, accuracy=1.000]\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "ITERACOES = 1_000_000\n",
    "iterator = tqdm(range(ITERACOES))\n",
    "X = batch_tokens[0, :].unsqueeze(0).to(device)\n",
    "y = batch_labels[0].unsqueeze(0).to(device)\n",
    "for _ in iterator:\n",
    "    y_hat = model(X)\n",
    "    loss = criterion(y_hat, y)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    acc = acc_metric(y, y_hat)\n",
    "    iterator.set_postfix({\"loss\": f\"{loss.item():6.3f}\", \"accuracy\": f\"{acc:.3f}\"})\n",
    "    if loss.item() <= 0.5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "10a244c6-8a99-4f1d-a93c-818553c418fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LABEL: 2\n",
      "PREDICT: 2\n",
      "PREDICT PROBA: [[0.059670496731996536, 0.07482034713029861, 0.6071296334266663, 0.15909965336322784, 0.09927991032600403]]\n"
     ]
    }
   ],
   "source": [
    "print(f'LABEL: {y.item()}')\n",
    "print(f'PREDICT: {torch.argmax(y_hat)}')\n",
    "print(f'PREDICT PROBA: {F.softmax(y_hat, dim=-1).tolist()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "dd045d77-53ff-496a-a21e-b5d1e5a7b8f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logit predict: [[-0.5622339248657227, -0.3359818458557129, 1.7576706409454346, 0.4184591472148895, -0.05312836170196533]] | true label: tensor([2], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(f'logit predict: {y_hat.tolist()} | true label: {y}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c857f6d4-70d7-4e0f-ac78-bdcbe52ecbe0",
   "metadata": {},
   "source": [
    "# Treinando em um Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "65073d89-c159-42b9-9667-34550d441756",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                             | 1727/1000000 [00:44<7:12:14, 38.49it/s, loss=0.100, accuracy=1.000]\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "ITERACOES = 1_000_000\n",
    "iterator = tqdm(range(ITERACOES))\n",
    "X = batch_tokens.to(device)\n",
    "y = batch_labels.to(device)\n",
    "for _ in iterator:\n",
    "    y_hat = model(X)\n",
    "    loss = criterion(y_hat, y)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    acc = acc_metric(y, y_hat)\n",
    "    iterator.set_postfix({\"loss\": f\"{loss.item():6.3f}\", \"accuracy\": f\"{acc:.3f}\"})\n",
    "    if loss.item() <= 0.1:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "dc27b0a5-fe4d-402b-8cbf-c403feb14a23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 2, 3, 0, 0, 2, 4, 3, 0, 3, 2, 4, 3, 3, 3, 2, 2, 2, 3, 1, 4, 3, 3, 3,\n",
       "        1, 0, 3, 0, 1, 2, 2, 3], device='cuda:0')"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(y_hat, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "832494bd-a364-42a5-b1e3-627bec1a5b4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 2, 3, 0, 0, 2, 4, 3, 0, 3, 2, 4, 3, 3, 3, 2, 2, 2, 3, 1, 4, 3, 3, 3,\n",
       "        1, 0, 3, 0, 1, 2, 2, 3], device='cuda:0')"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f5f1c7-8a83-4ba7-b9bd-c9fd8d067dcb",
   "metadata": {},
   "source": [
    "# Treinando para o conjunto de dados inteiro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "5a359c4a-5487-46b1-80d5-257524a50a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def eval_model(model, data_eval) -> None:\n",
    "    model.eval()\n",
    "    acc_list = []\n",
    "    for i, batch in enumerate(data_eval):\n",
    "        labels, tokens, texts = batch['label'], batch['tokens'], batch['text']\n",
    "        labels, tokens = labels.to(device), tokens.to(device)\n",
    "\n",
    "        predict = model(tokens)\n",
    "        predict = torch.argmax(predict, dim=1)\n",
    "        acc = torch.mean((predict == labels).float()).item()\n",
    "        acc_list.append(acc)\n",
    "    acc_tensor = torch.tensor(acc_list)\n",
    "    return round(torch.mean(acc_tensor).item(), 3)\n",
    "\n",
    "\n",
    "def train_model(model, data_train, data_eval, epochs, optimizer, criterion) -> None:\n",
    "    model.train()\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss_eval_list: list = []\n",
    "    acc_eval = 0.0\n",
    "    for epoch in range(epochs):\n",
    "        torch.cuda.empty_cache()\n",
    "        loss_epoch = 0.0\n",
    "        batch_iterator = tqdm(data_train, desc=f\"Processing Epoch {epoch:02d}\")\n",
    "        for batch in batch_iterator:\n",
    "            labels, tokens, texts = batch['label'], batch['tokens'], batch['text']\n",
    "            labels, tokens = labels.to(device), tokens.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(tokens)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            acc = acc_metric(labels, outputs)\n",
    "            \n",
    "            batch_iterator.set_postfix({\"loss\": f\"{loss.item():6.3f}\", \"accuracy train\": f\"{acc:.3f}\", \"accuracy eval\": f\"{acc_eval:.3f}\"})\n",
    "            \n",
    "        acc_eval = eval_model(model, data_eval)\n",
    "        loss_eval_list.append(acc_eval)\n",
    "    return loss_eval_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7d5d21-e188-422d-ab34-7d9f1e6d621d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Epoch 04: 100%|█| 20313/20313 [12:47<00:00, 26.48it/s, loss=0.956, accuracy train=0.562, accuracy eval=0.559\n",
      "Processing Epoch 07: 100%|█| 20313/20313 [12:46<00:00, 26.51it/s, loss=1.127, accuracy train=0.500, accuracy eval=0.572\n",
      "Processing Epoch 10: 100%|█| 20313/20313 [12:47<00:00, 26.48it/s, loss=1.059, accuracy train=0.562, accuracy eval=0.576\n",
      "Processing Epoch 15: 100%|█| 20313/20313 [2:24:55<00:00,  2.34it/s, loss=0.904, accuracy train=0.500, accuracy eval=0.5\n",
      "Processing Epoch 16: 100%|█| 20313/20313 [13:11<00:00, 25.66it/s, loss=0.812, accuracy train=0.750, accuracy eval=0.583\n",
      "Processing Epoch 18: 100%|█| 20313/20313 [13:22<00:00, 25.32it/s, loss=1.311, accuracy train=0.438, accuracy eval=0.585\n",
      "Processing Epoch 19:  81%|▊| 16408/20313 [10:56<02:35, 25.05it/s, loss=0.916, accuracy train=0.625, accuracy eval=0.583"
     ]
    }
   ],
   "source": [
    "loss_eval_list = train_model(model, train_loader, test_loader, epochs=EPOCHS, optimizer=optimizer, criterion=criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "5cabb020-b30e-41f3-ac16-b19d3e4d496d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvando o modelo\n",
    "file_path = 'models/yepreview_model_.pth'\n",
    "torch.save(model.state_dict(), file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "806a9b97-7f44-460c-bd9a-927880de67e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(test_loader))\n",
    "batch_labels, batch_tokens, batch_texts = batch['label'], batch['tokens'], batch['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "944a53da-5da0-4349-814e-65175c0aeefb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model(batch_tokens.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "0a470f15-3db5-4d60-a23d-2f2a5e872162",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 4, 3, 3, 2, 0, 0, 3, 2, 4, 1, 4, 2, 0, 0, 3, 3, 0, 1, 1, 0, 2, 3, 1,\n",
       "        0, 1, 3, 1, 2, 4, 0, 3])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "d0b446e0-1726-4fbe-9eee-d5a9c8e7c961",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 4, 3, 3, 4, 0, 2, 4, 2, 4, 2, 4, 1, 0, 0, 3, 0, 0, 1, 1, 3, 2, 4, 2,\n",
       "        1, 1, 3, 1, 2, 4, 0, 3], device='cuda:0')"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(pred, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "6d144e91-172e-4896-bbd3-f85f9ed3118f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6875"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_metric(batch_labels.to(device), pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c0c23a-6f7e-4313-a9d7-acbe4c0bb036",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
