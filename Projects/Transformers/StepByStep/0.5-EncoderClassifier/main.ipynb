{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "166cd3e4-c009-46ac-afce-96ce2dc0bf5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d81915ae-1aa8-4461-a4dc-ff64ac7a5af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "053a2838-d620-4970-b6cc-0c2ccbe09a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c7a5a55-f669-41f3-8a8a-d364be4b342d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ffb5bd0-0350-42c7-b8b5-1ab86b030480",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a54e09be-d478-4384-85d0-ad71723af024",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6dc91a4c-4bb9-469e-a2b1-d5e202a937f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b713644e-ec5b-4519-8103-69cf01805e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f94bfb2b-677c-4831-ac07-4c16c9829dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download dataset\n",
    "dataset = load_dataset(\"AiresPucrs/google-play-apps-review-pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1f91179d-c529-4f1d-9e8d-1a995146f921",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ec73ce17-b7a7-49c4-aa21-03d2d186cdd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c15009-3b07-499a-a876-2fa4537b85dc",
   "metadata": {},
   "source": [
    "# Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dc771a05-fb00-4072-80e3-0348f5626083",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"pierreguillou/bert-base-cased-squad-v1.1-portuguese\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2c522b02-a250-4ab3-a272-81dc9ade88f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "texto = 'Esse texto que será tokenizado.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "18c7ff48-89d6-4ac5-ae72-23c9a415a5fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOKENS BERT BASE PT-BT: ['Esse', 'texto', 'que', 'será', 'to', '##ken', '##izado', '.']\n"
     ]
    }
   ],
   "source": [
    "tokens = tokenizer.tokenize(texto)\n",
    "print(f'TOKENS BERT BASE PT-BT: {tokens}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0a866efe-5bf7-488d-b4c6-d8a3e6fc46b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29794"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VOCAB_SIZE = tokenizer.vocab_size\n",
    "VOCAB_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eaa8258d-808c-4f19-b400-bf07eada83fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOKENS IDS: [101, 3758, 4054, 179, 2810, 374, 8110, 2303, 119, 102]\n"
     ]
    }
   ],
   "source": [
    "token_ids = tokenizer.encode(texto, add_special_tokens=True)\n",
    "print(f'TOKENS IDS: {token_ids}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9430d7ad-fc39-4b84-acf0-a5ce3b2fda32",
   "metadata": {},
   "source": [
    "# Adicionando normalizer ao tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7edf00ff-c620-4a4a-abee-feb063227aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers.normalizers import NFKC, Lowercase, StripAccents, Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5cfb9571-6df8-4783-9a5a-5d61a2a69e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_normalizer = Sequence([NFKC(), Lowercase(), StripAccents()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7a6e3ded-ea4c-42e5-93dc-344085afead0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.backend_tokenizer.normalizer = custom_normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "83b08eb2-62c7-428d-bbf2-3e0affcc8b25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOKENS BERT BASE PT-BT: ['Esse', 'texto', 'que', 'será', 'to', '##ken', '##izado', '.']\n",
      "['[CLS]', 'isso', 'é', 'um', 'teste', 'com', 'ace', '##ntos', 'e', 'caracteres', 'especiais', 'como', ':', '[UNK]', ',', '[UNK]', ',', 'é', '!', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "text = \"Isso é um TESTE com ACENTOS e caracteres especiais como: ç, ã, é!\"\n",
    "encoded = tokenizer(text)\n",
    "print(f'TOKENS BERT BASE PT-BT: {tokens}')\n",
    "print(tokenizer.convert_ids_to_tokens(encoded[\"input_ids\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6d6db975-7995-488b-850b-18d537e257ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[101, 1257, 253, 222, 3515, 170, 10049, 850, 122, 12962, 4797, 271, 131, 100, 117, 100, 117, 253, 106, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "encoded = tokenizer(text, padding='max_length', max_length=124, truncation=True)\n",
    "print(encoded['input_ids'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1257263f-61eb-4fd6-b86e-6e6c08e8518e",
   "metadata": {},
   "source": [
    "# MODEL CONFIG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "34a6b331-d672-4e31-8f8b-b772aa0c2890",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0001"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9b069b6a-a014-4a0a-8337-bcb1f63df78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = tokenizer.vocab_size\n",
    "SEQ_LEN = 256\n",
    "D_MODEL = 64\n",
    "N_LAYERS = 6\n",
    "N_HEADS = 4\n",
    "N_OUTPUT = 1\n",
    "HIDDEN_SIZE = 512\n",
    "DROPOUT = 0.1\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 50\n",
    "DROPOUT = 0.10\n",
    "LR = 1e-3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f73842-edfe-47c3-abd0-398f75cd3bea",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "36ba2efb-cc18-4afc-8f4a-17c78527b52b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['review', 'sentiment'],\n",
       "        num_rows: 20000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f1fc6573-bf0d-4f72-9aab-0c7a014a1119",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEAN WORDS BY TEXT: 63.9267\n",
      "STD WORDS BY TEXT: 16.53660264715821\n"
     ]
    }
   ],
   "source": [
    "# Calculating the average of texts\n",
    "mean_words_text = np.mean(\n",
    "    list(map(lambda x: len(x.split()), dataset[\"train\"]['review']))\n",
    ")\n",
    "\n",
    "std_words_text = np.std(\n",
    "    list(map(lambda x: len(x.split()), dataset[\"train\"]['review']))\n",
    ")\n",
    "print(f'MEAN WORDS BY TEXT: {mean_words_text}')\n",
    "print(f'STD WORDS BY TEXT: {std_words_text}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0add57f4-4838-4926-bb6d-f26103ceb6cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'voces precisam cobrar dos entregadores que se comuniquem nao faz sentido o restaurante colocar o pedido como finalizado o entregador estar la e demorar mais de 30minutos para sair alguem passou a informacao errada ai vc pede esclarecimentos ao entregador via chat ele nao responde liga ele nao atende ai na entrega chega com cara de banda falando que o restaurante atrasou se foi isso pq nao respondeu quando foi questionado isso e muito frequente alias raridade e quando nao acontece'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'][11_000]['review']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9fc474cb-654c-4f9a-8e05-07b32cf049fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'][11_000]['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d81614c1-8d95-4dbb-8b90-b3ffae1c145b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NUM TOKENS WITHOUT TRUNCATION: 236\n",
      "NUM TOKENS WITH TRUCATION 124\n"
     ]
    }
   ],
   "source": [
    "print('NUM TOKENS WITHOUT TRUNCATION:', len(tokenizer(dataset['train'][0]['review'])['input_ids']))\n",
    "print('NUM TOKENS WITH TRUCATION', len(\n",
    "    tokenizer(\n",
    "        dataset['train'][0]['review'],\n",
    "        padding='max_length',\n",
    "        max_length=124,\n",
    "        truncation=True)\n",
    "    ['input_ids'])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cf65b709-337c-4671-b924-39255ba059d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['train'] = dataset['train'].shuffle(seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "312902b5-314b-4ecc-b70c-a08b4a30b253",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(dataset['train'][0]['sentiment']).view(1, 1).to(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "40ca7c93-0e15-4d32-b983-8e8841d0bf7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GooglePlayAppsReviewClassifier(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dataset,\n",
    "        tokenizer = tokenizer,\n",
    "        seq_len: int = SEQ_LEN,\n",
    "        vocab_size: int = VOCAB_SIZE\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.dataset = dataset\n",
    "        self.tokenizer = tokenizer\n",
    "        self.seq_len = seq_len\n",
    "        self.vocab_size = vocab_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.dataset['train'].num_rows\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        text = dataset['train'][index]['review']\n",
    "        X_token = self.tokenizer(\n",
    "            text,\n",
    "            padding='max_length',\n",
    "            max_length=self.seq_len,\n",
    "            truncation=True\n",
    "        )['input_ids']\n",
    "        y = torch.tensor(dataset['train'][index]['sentiment'])\n",
    "        y = y.view(1)\n",
    "        return {\n",
    "            'text': text,\n",
    "            'tokens': torch.tensor(X_token),\n",
    "            'label': y.to(torch.float32)\n",
    "        }        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3b6d5988-e558-49eb-affc-c994a141453a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = GooglePlayAppsReviewClassifier(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6f58033e-3dfd-4db0-8567-d981826a51b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'parece que a cada atualizacao a frequencia dos anuncios aumentam e invadem cada vez mais os videos horrivel isso ha poucos anos atras nao ocorria essas publicidades invasivas e desnecessarias desanima qualquer um que esta na plataforma apreciando conteudo principalmente pelo smartphone e tira o foco total do video execucao e opcoes de qualidade de video interessantes mas deviam rever essa politica de publicidade pq ta invasiva demais',\n",
       " 'tokens': tensor([  101,  4048,   179,   123,  1078,  2233,  2446,   304, 22280,   123,\n",
       "          1864,  3292,   298,  2043,   128, 20958,   122,  5808,   210,  1078,\n",
       "           576,   325,   259, 12456, 22281,  3428, 15558, 22290,  1257,   607,\n",
       "          3885,   481,  7521,   229, 22280,  3719,   151,  3867, 10834, 22281,\n",
       "          3819,  4521,   122, 15310,  1347, 14348,  1950,  4029,   148,  1569,\n",
       "           222,   179,   418,   229,  6326,  2533,   351,   214,  1519,  1350,\n",
       "          1953,   423,   139, 14254, 19894,   514,   122,  4551,   146,  7407,\n",
       "          1437,   171, 12456,  2246,   304, 22280,   122,  2134,   303,   143,\n",
       "           125,  3322,   125, 12456, 20764,   449, 21494,  7871,  1921, 12067,\n",
       "           232,   125, 10834,   126, 22298,   316,  3819,  1319,  3547,   102,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0]),\n",
       " 'label': tensor([0.])}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ea202399-00b2-41fb-b55d-13cf37013400",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, shuffle=False, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f9966d-5c55-4a48-b6cf-198e76b8fb71",
   "metadata": {},
   "source": [
    "# MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "61c31043-f539-4fe1-a136-92c32b3a6f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model: int = D_MODEL, dropout: float = 0.01, seq_len: int = SEQ_LEN):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        \n",
    "        pe = torch.zeros(SEQ_LEN, D_MODEL)\n",
    "        k = torch.arange(0, seq_len).unsqueeze(1) \n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * -(math.log(10_000) / d_model))\n",
    "        # sine for even indices\n",
    "        pe[:, 0::2] = torch.sin(k * div_term)\n",
    "        # cos for odd indices\n",
    "        pe[:, 1::2] = torch.cos(k * div_term)\n",
    "        # add batch dim\n",
    "        pe = pe.unsqueeze(0)\n",
    "\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x: Tensor):\n",
    "        x = x + self.pe[:, :x.size(1)].requires_grad_(False)\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "75039bda-3e8e-4140-a26e-7b442d3cce48",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GooglePlayAppsReviewModel(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        seq_len: int = SEQ_LEN,\n",
    "        d_model: int = D_MODEL,\n",
    "        vocab_size: int = VOCAB_SIZE,\n",
    "        num_heads: int = N_HEADS,\n",
    "        nx: int = N_LAYERS,\n",
    "        n_outputs: int = N_OUTPUT,\n",
    "        dropout: float = DROPOUT,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.seq_len = seq_len\n",
    "        self.d_model = d_model\n",
    "        self.vocab_size = vocab_size\n",
    "        self.num_heads = num_heads\n",
    "        self.nx = nx\n",
    "        self.dropout = dropout\n",
    "        self.n_outputs = n_outputs\n",
    "\n",
    "        self.embedding_layer = nn.Embedding(\n",
    "            num_embeddings=self.vocab_size,\n",
    "            embedding_dim=self.d_model,\n",
    "            padding_idx=0\n",
    "        )\n",
    "\n",
    "        self.positional_encoding = PositionalEncoding(\n",
    "            d_model=self.d_model,\n",
    "            dropout=self.dropout,\n",
    "            seq_len=self.seq_len\n",
    "        )\n",
    "\n",
    "        self.encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=self.d_model,\n",
    "            nhead=self.num_heads,\n",
    "            dropout=self.dropout,\n",
    "            norm_first=True,\n",
    "            batch_first=True,\n",
    "            activation='gelu'\n",
    "        )\n",
    "        self.encoder_block = nn.TransformerEncoder(\n",
    "            self.encoder_layer,\n",
    "            num_layers=self.nx\n",
    "        )\n",
    "\n",
    "        self.linear = nn.Sequential(\n",
    "            nn.Linear(self.d_model, self.d_model * 2),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(self.d_model * 2, self.d_model),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(self.d_model, self.d_model),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(self.d_model, self.d_model // 4),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(self.d_model // 4, self.d_model // 8),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(self.d_model // 8, self.d_model // 16)\n",
    "        )\n",
    "\n",
    "        self.output = nn.Sequential(\n",
    "            nn.Linear(self.d_model // 16, self.d_model // 32),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(self.d_model // 32, self.d_model // self.d_model),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding_layer(x)\n",
    "        x = self.positional_encoding(x)\n",
    "        x = self.encoder_block(x)\n",
    "        # Pegando a representação vetorial do token <CLS>\n",
    "        x = x[:, 0, :]\n",
    "\n",
    "        x = self.linear(x)\n",
    "        x = self.output(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "deaa4db4-95e1-46af-abe5-691a48a7f8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GooglePlayAppsReviewModel().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b20433a4-fff7-4e0b-9fae-2488f0dc0b50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                                            Param #\n",
       "==========================================================================================\n",
       "GooglePlayAppsReviewModel                                         --\n",
       "├─Embedding: 1-1                                                  1,906,816\n",
       "├─PositionalEncoding: 1-2                                         --\n",
       "│    └─Dropout: 2-1                                               --\n",
       "├─TransformerEncoderLayer: 1-3                                    --\n",
       "│    └─MultiheadAttention: 2-2                                    12,480\n",
       "│    │    └─NonDynamicallyQuantizableLinear: 3-1                  4,160\n",
       "│    └─Linear: 2-3                                                133,120\n",
       "│    └─Dropout: 2-4                                               --\n",
       "│    └─Linear: 2-5                                                131,136\n",
       "│    └─LayerNorm: 2-6                                             128\n",
       "│    └─LayerNorm: 2-7                                             128\n",
       "│    └─Dropout: 2-8                                               --\n",
       "│    └─Dropout: 2-9                                               --\n",
       "├─TransformerEncoder: 1-4                                         --\n",
       "│    └─ModuleList: 2-10                                           --\n",
       "│    │    └─TransformerEncoderLayer: 3-2                          281,152\n",
       "│    │    └─TransformerEncoderLayer: 3-3                          281,152\n",
       "│    │    └─TransformerEncoderLayer: 3-4                          281,152\n",
       "│    │    └─TransformerEncoderLayer: 3-5                          281,152\n",
       "│    │    └─TransformerEncoderLayer: 3-6                          281,152\n",
       "│    │    └─TransformerEncoderLayer: 3-7                          281,152\n",
       "├─Sequential: 1-5                                                 --\n",
       "│    └─Linear: 2-11                                               8,320\n",
       "│    └─GELU: 2-12                                                 --\n",
       "│    └─Linear: 2-13                                               8,256\n",
       "│    └─GELU: 2-14                                                 --\n",
       "│    └─Linear: 2-15                                               4,160\n",
       "│    └─GELU: 2-16                                                 --\n",
       "│    └─Linear: 2-17                                               1,040\n",
       "│    └─GELU: 2-18                                                 --\n",
       "│    └─Linear: 2-19                                               136\n",
       "│    └─GELU: 2-20                                                 --\n",
       "│    └─Linear: 2-21                                               36\n",
       "├─Sequential: 1-6                                                 --\n",
       "│    └─Linear: 2-22                                               10\n",
       "│    └─GELU: 2-23                                                 --\n",
       "│    └─Linear: 2-24                                               3\n",
       "│    └─Sigmoid: 2-25                                              --\n",
       "==========================================================================================\n",
       "Total params: 3,896,841\n",
       "Trainable params: 3,896,841\n",
       "Non-trainable params: 0\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "41acd5a3-d1ff-4bc6-bd17-b308ad3a0cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(train_loader))\n",
    "batch_labels, batch_tokens, batch_texts = batch['label'], batch['tokens'], batch['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "00b94b66-66c6-4c9a-9eb0-01f6b5ce7d80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  101,   146,   305,  ...,     0,     0,     0],\n",
       "        [  101,   146,   305,  ...,     0,     0,     0],\n",
       "        [  101, 12044,   311,  ...,     0,     0,     0],\n",
       "        ...,\n",
       "        [  101, 20933,   678,  ...,     0,     0,     0],\n",
       "        [  101,   146,   305,  ...,     0,     0,     0],\n",
       "        [  101,  8766,   185,  ...,     0,     0,     0]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "aaff8e86-3426-47fb-a554-3c8b209c6c12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  101,   146,   305, 22291,   495,  4062,  2535,   418,  7264,  1415,\n",
       "         2394,   368, 17105,   348,   123,  7179,   202,  7343,   237, 22336,\n",
       "         9570, 22281,   700,   180,   169,  8388,  2233,  2446,   304, 22280,\n",
       "          229, 22280,  7674, 18691,   926,  8977,   538,  4395,   553,   122,\n",
       "          229, 22280, 21174,  1941,  1114,   244,   125,   925,  2421, 22281,\n",
       "         1176,   240,  1966,  3350,  1941,   418,   229,  5314,   125,  8416,\n",
       "         1257,   229, 22280,  7093, 22287,   625, 13956, 19508,  5698,   244,\n",
       "         7122, 11175,   304, 22280, 12044,  1004, 17497, 12966,   170, 14730,\n",
       "         2394,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_tokens[1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "934aa783-8577-4d71-940b-e565fb5cd121",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_labels[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ed231f52-d460-486f-97c4-f91530ce1d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = batch_tokens[1, :].unsqueeze(0).to(device)\n",
    "y = batch_labels[1].to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "aa27c3b0-ede2-4c5c-9c20-653566cf5b58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(X).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "780aebb2-a852-4018-bcc1-6cd56232de38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "67c74e32-a94d-4c41-9284-51d7f0874b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "11e9dcec-0613-4521-aefd-b8123e51bb56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5114, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion(model(X), y.unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "68647775-a460-44d2-855a-a0005aefde02",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 21/1000000 [00:00<5:58:32, 46.48it/s, loss=0.004]\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "ITERACOES = 1_000_000\n",
    "iterator = tqdm(range(ITERACOES))\n",
    "for _ in iterator:\n",
    "    y_hat = model(X)\n",
    "    \n",
    "    loss = criterion(y_hat, y.unsqueeze(0))\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    iterator.set_postfix({\"loss\": f\"{loss.item():6.3f}\"})\n",
    "    if loss.item() <= 0.01:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61754451-f732-48c8-88a8-b5832987090a",
   "metadata": {},
   "source": [
    "# Trienando em um batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f20f7ca1-7dba-44bd-827a-2ac4e12755fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = batch_tokens\n",
    "y = batch_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "bb23c25a-8c06-456e-8705-f60d05285eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = X.to(device), y.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "5d362d22-6d06-468f-b706-e2681493b5aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 177/1000000 [00:11<18:09:49, 15.29it/s, loss=0.096]\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "ITERACOES = 1_000_000\n",
    "iterator = tqdm(range(ITERACOES))\n",
    "for _ in iterator:\n",
    "    y_hat = model(X)\n",
    "    loss = criterion(y_hat, y)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    iterator.set_postfix({\"loss\": f\"{loss.item():6.3f}\"})\n",
    "    if loss.item() <= 0.1:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "29bcb17e-fe8c-44c8-84cb-34803b974205",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0., 1.,\n",
       "        1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1.],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.where(y_hat > 0.5, torch.tensor(1.0), torch.tensor(0.0)).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "96756b10-fac2-4db9-b08f-3ee4382f7062",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0., 1.,\n",
       "        1., 0., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1.],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "325057ba-53a4-4111-8ae4-bd6989823a93",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Epoch 00: 100%|██████████| 625/625 [00:52<00:00, 11.87it/s, loss=0.501]\n",
      "Processing Epoch 01: 100%|██████████| 625/625 [00:52<00:00, 11.84it/s, loss=0.445]\n",
      "Processing Epoch 02: 100%|██████████| 625/625 [00:52<00:00, 11.86it/s, loss=0.388]\n",
      "Processing Epoch 03: 100%|██████████| 625/625 [00:52<00:00, 11.84it/s, loss=0.435]\n",
      "Processing Epoch 04: 100%|██████████| 625/625 [00:52<00:00, 11.84it/s, loss=0.486]\n",
      "Processing Epoch 05: 100%|██████████| 625/625 [00:52<00:00, 11.85it/s, loss=0.405]\n",
      "Processing Epoch 06: 100%|██████████| 625/625 [00:52<00:00, 11.84it/s, loss=0.412]\n",
      "Processing Epoch 07: 100%|██████████| 625/625 [00:52<00:00, 11.85it/s, loss=0.451]\n",
      "Processing Epoch 08: 100%|██████████| 625/625 [00:52<00:00, 11.85it/s, loss=0.320]\n",
      "Processing Epoch 09: 100%|██████████| 625/625 [00:52<00:00, 11.85it/s, loss=0.352]\n",
      "Processing Epoch 10: 100%|██████████| 625/625 [00:52<00:00, 11.87it/s, loss=0.338]\n",
      "Processing Epoch 11: 100%|██████████| 625/625 [00:52<00:00, 11.85it/s, loss=0.301]\n",
      "Processing Epoch 12: 100%|██████████| 625/625 [00:52<00:00, 11.88it/s, loss=0.346]\n",
      "Processing Epoch 13: 100%|██████████| 625/625 [00:52<00:00, 11.85it/s, loss=0.282]\n",
      "Processing Epoch 14: 100%|██████████| 625/625 [00:52<00:00, 11.85it/s, loss=0.291]\n",
      "Processing Epoch 15: 100%|██████████| 625/625 [00:52<00:00, 11.83it/s, loss=0.311]\n",
      "Processing Epoch 16: 100%|██████████| 625/625 [00:52<00:00, 11.82it/s, loss=0.308]\n",
      "Processing Epoch 17: 100%|██████████| 625/625 [00:52<00:00, 11.85it/s, loss=0.321]\n",
      "Processing Epoch 18: 100%|██████████| 625/625 [00:52<00:00, 11.86it/s, loss=0.294]\n",
      "Processing Epoch 19: 100%|██████████| 625/625 [00:52<00:00, 11.88it/s, loss=0.476]\n",
      "Processing Epoch 20: 100%|██████████| 625/625 [00:52<00:00, 11.84it/s, loss=0.288]\n",
      "Processing Epoch 21: 100%|██████████| 625/625 [00:52<00:00, 11.86it/s, loss=0.274]\n",
      "Processing Epoch 22: 100%|██████████| 625/625 [00:52<00:00, 11.86it/s, loss=0.289]\n",
      "Processing Epoch 23: 100%|██████████| 625/625 [00:52<00:00, 11.84it/s, loss=0.152]\n",
      "Processing Epoch 24: 100%|██████████| 625/625 [00:52<00:00, 11.86it/s, loss=0.178]\n",
      "Processing Epoch 25: 100%|██████████| 625/625 [00:52<00:00, 11.86it/s, loss=0.370]\n",
      "Processing Epoch 26: 100%|██████████| 625/625 [00:52<00:00, 11.88it/s, loss=0.346]\n",
      "Processing Epoch 27: 100%|██████████| 625/625 [00:52<00:00, 11.86it/s, loss=0.260]\n",
      "Processing Epoch 28: 100%|██████████| 625/625 [00:52<00:00, 11.85it/s, loss=0.299]\n",
      "Processing Epoch 29: 100%|██████████| 625/625 [00:52<00:00, 11.84it/s, loss=0.262]\n",
      "Processing Epoch 30: 100%|██████████| 625/625 [00:52<00:00, 11.84it/s, loss=0.167]\n",
      "Processing Epoch 31: 100%|██████████| 625/625 [00:52<00:00, 11.87it/s, loss=0.238]\n",
      "Processing Epoch 32: 100%|██████████| 625/625 [00:52<00:00, 11.85it/s, loss=0.280]\n",
      "Processing Epoch 33: 100%|██████████| 625/625 [00:52<00:00, 11.86it/s, loss=0.209]\n",
      "Processing Epoch 34: 100%|██████████| 625/625 [00:52<00:00, 11.84it/s, loss=0.192]\n",
      "Processing Epoch 35: 100%|██████████| 625/625 [00:52<00:00, 11.83it/s, loss=0.145]\n",
      "Processing Epoch 36: 100%|██████████| 625/625 [00:52<00:00, 11.84it/s, loss=0.113]\n",
      "Processing Epoch 37: 100%|██████████| 625/625 [00:52<00:00, 11.85it/s, loss=0.197]\n",
      "Processing Epoch 38: 100%|██████████| 625/625 [00:52<00:00, 11.84it/s, loss=0.148]\n",
      "Processing Epoch 39: 100%|██████████| 625/625 [00:52<00:00, 11.84it/s, loss=0.059]\n",
      "Processing Epoch 40: 100%|██████████| 625/625 [00:52<00:00, 11.87it/s, loss=0.245]\n",
      "Processing Epoch 41: 100%|██████████| 625/625 [00:52<00:00, 11.83it/s, loss=0.076]\n",
      "Processing Epoch 42: 100%|██████████| 625/625 [00:52<00:00, 11.84it/s, loss=0.145]\n",
      "Processing Epoch 43: 100%|██████████| 625/625 [00:52<00:00, 11.87it/s, loss=0.030]\n",
      "Processing Epoch 44: 100%|██████████| 625/625 [00:52<00:00, 11.86it/s, loss=0.061]\n",
      "Processing Epoch 45: 100%|██████████| 625/625 [00:52<00:00, 11.87it/s, loss=0.035]\n",
      "Processing Epoch 46: 100%|██████████| 625/625 [00:52<00:00, 11.85it/s, loss=0.098]\n",
      "Processing Epoch 47: 100%|██████████| 625/625 [00:52<00:00, 11.84it/s, loss=0.096]\n",
      "Processing Epoch 48: 100%|██████████| 625/625 [00:52<00:00, 11.84it/s, loss=0.017]\n",
      "Processing Epoch 49: 100%|██████████| 625/625 [00:52<00:00, 11.83it/s, loss=0.087]\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "optimizer.zero_grad(set_to_none=True)\n",
    "loss_eval_list: list = []\n",
    "for epoch in range(EPOCHS):\n",
    "    torch.cuda.empty_cache()\n",
    "    loss_epoch = 0.0\n",
    "    batch_iterator = tqdm(train_loader, desc=f\"Processing Epoch {epoch:02d}\")\n",
    "    for batch in batch_iterator:\n",
    "        labels, tokens, texts = batch['label'], batch['tokens'], batch['text']\n",
    "        labels, tokens = labels.to(device), tokens.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(tokens)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        batch_iterator.set_postfix({\"loss\": f\"{loss.item():6.3f}\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "187a8d63-a37c-4d6d-8883-8294637aaf5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "model_file_path = Path('model/google_play_apps_review_model.pth')\n",
    "torch.save(model.state_dict(), model_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "e8268279-3f8a-4a29-954d-6f4edd2a0090",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0., 1.,\n",
       "        1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1.],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.where(y_hat > 0.5, torch.tensor(1.0), torch.tensor(0.0)).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "57730e17-ef53-4309-a667-0782cd0c454e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0., 1.,\n",
       "        1., 0., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1.],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2544e9ce-dd28-4d3a-8e64-4571ca611ffa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    }
   ],
   "source": [
    "model_inference = GooglePlayAppsReviewModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2d0198f9-6d16-4e80-b929-fb1ec6532c33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GooglePlayAppsReviewModel(\n",
       "  (embedding_layer): Embedding(29794, 64, padding_idx=0)\n",
       "  (positional_encoding): PositionalEncoding(\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder_layer): TransformerEncoderLayer(\n",
       "    (self_attn): MultiheadAttention(\n",
       "      (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
       "    )\n",
       "    (linear1): Linear(in_features=64, out_features=2048, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (linear2): Linear(in_features=2048, out_features=64, bias=True)\n",
       "    (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "    (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "    (dropout1): Dropout(p=0.1, inplace=False)\n",
       "    (dropout2): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder_block): TransformerEncoder(\n",
       "    (layers): ModuleList(\n",
       "      (0-5): 6 x TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=64, out_features=2048, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=2048, out_features=64, bias=True)\n",
       "        (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (linear): Sequential(\n",
       "    (0): Linear(in_features=64, out_features=128, bias=True)\n",
       "    (1): GELU(approximate='none')\n",
       "    (2): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (3): GELU(approximate='none')\n",
       "    (4): Linear(in_features=64, out_features=64, bias=True)\n",
       "    (5): GELU(approximate='none')\n",
       "    (6): Linear(in_features=64, out_features=16, bias=True)\n",
       "    (7): GELU(approximate='none')\n",
       "    (8): Linear(in_features=16, out_features=8, bias=True)\n",
       "    (9): GELU(approximate='none')\n",
       "    (10): Linear(in_features=8, out_features=4, bias=True)\n",
       "  )\n",
       "  (output): Sequential(\n",
       "    (0): Linear(in_features=4, out_features=2, bias=True)\n",
       "    (1): GELU(approximate='none')\n",
       "    (2): Linear(in_features=2, out_features=1, bias=True)\n",
       "    (3): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "model_file_path = Path('model/google_play_apps_review_model.pth')\n",
    "model_inference.load_state_dict(torch.load(model_file_path, map_location=torch.device(device)))\n",
    "model_inference.eval()  # Coloca o modelo em modo de avaliação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4088ab37-5e36-4f4a-b121-1878641ef8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_review = \"\"\"\n",
    "depois de um problema com um pedido que veio incorreto, o distribuidor culpou o app por nao disponibilizar os itens oferecidos, \n",
    "e por isso acabei recebendo menos do que paguei. apos essa resposta, fiz uma avaliacao negativa e, logo depois, recebi uma\n",
    "ligacao do distribuidor, que supostamente seria para resolver o problema, mas acabou afirmando que nao gostou da avaliacao e que eu \n",
    "estava agindo de ma fe. acabei ficando no prejuizo e ainda fui tratado com hostilidade. por isso, nao recomendo o app. tambem tentei \n",
    "contato por email, mas a mensagem foi rejeitada.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8ae0bcc2-dc2a-4054-8068-65158ec549f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_review = \"\"\"\n",
    "depois de um pedido que veio corretamente, o distribuidor elogiou o app por fornecer todos os itens oferecidos, e por isso recebi \n",
    "exatamente o que paguei. apos essa resposta, fiz uma avaliacao positiva e, logo depois, recebi uma ligacao do distribuidor, que foi\n",
    "para agradecer pela avaliacao e reforcar que tudo estava certo. fiquei satisfeito com o atendimento e fui tratado com muita cordialidade.\n",
    "por isso, recomendo o app. tambem tentei contato por email, e a mensagem foi recebida sem problemas.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7406d420-2723-40d5-86d8-49be327c2b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_tokenized = tokenizer(\n",
    "            negative_review,\n",
    "            padding='max_length',\n",
    "            max_length=SEQ_LEN,\n",
    "            truncation=True\n",
    "        )['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e32cd385-f27f-46c3-9f64-0322584c942b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0023]], grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_inference(torch.tensor(text_tokenized).unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7a2087d4-986e-48bc-b1d4-d8c7306e8770",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_tokenized = tokenizer(\n",
    "            positive_review,\n",
    "            padding='max_length',\n",
    "            max_length=SEQ_LEN,\n",
    "            truncation=True\n",
    "        )['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3bddbfa9-e43a-4e0c-80d2-f3a2cf327cf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9999]], grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_inference(torch.tensor(text_tokenized).unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22453dd3-8531-49bd-84a4-bcde2f9a5051",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
